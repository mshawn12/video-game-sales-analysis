# video-game-sales-analysis
Using a Python Flask-powered API, HTML/CSS, Javascript and SQL to test hypotheses about video game sales
<img src="https://github.com/mshawn12/video-game-sales-analysis/blob/main/images/video-game-header.png?raw=true">

## Background Information
The team will leverage a Global Video Game Sales & Ratings dataset from Kaggle (https://www.kaggle.com/datasets/thedevastator/global-video-game-sales-ratings) in order to test various hypotheses about video game genres.


## Process
- Step 1: Creating Jupyter Notebook to load, clean, and export Excel files as CSVs
<img src="https://github.com/mshawn12/video-game-sales-analysis/blob/main/images/jupyter-notebook.png?raw=true">

- Step 2: Creating an ERD Diagram using https://app.quickdatabasediagrams.com/ to develop SQL schema
<img src="https://github.com/mshawn12/video-game-sales-analysis/blob/main/images/ERD-Process.png?raw=true">

- Step 3: Leveraging pgAdmin and SQL to...
<img src="https://github.com/mshawn12/video-game-sales-analysis/blob/main/images/postgres-sql-steps.png?raw=true">

## Requirements
For Project 3, you will work with your group to tell a story using data visualizations. Here are the specific requirements:
- Your visualization must include a Python Flask-powered API, HTML/CSS, JavaScript, and at least one database (SQL, MongoDB, SQLite, etc.).
- Your project should fall into one of the following three tracks:
    - A combination of web scraping and Leaflet or Plotly
    - A dashboard page with multiple charts that update from the same data
    - A server that performs multiple manipulations on data in a database prior to visualization (must be approved)
- Your project should include at least one JS library that we did not cover.
- Your project must be powered by a dataset with at least 100 records.
- Your project must include some level of user-driven interaction (e.g., menus, dropdowns, textboxes).
- Your final visualization should ideally include at least three views.

### Data Cleanup and Analysis
Now that you’ve picked your data, it’s time to tackle development and analysis. This is where the fun starts!

The analysis process can be broken into two broad phases: (1) exploration and cleanup, and (2) analysis.

As you’ve learned, you’ll need to explore, clean, and reformat your data before you can begin answering your research questions. We recommend keeping track of these exploration and cleanup steps in a dedicated Jupyter notebook to keep you organized and make it easier to present your work later.

After you’ve cleaned your data and are ready to start crunching numbers, you should track your work in a Jupyter notebook dedicated specifically to analysis. We recommend focusing your analysis on multiple techniques, such as aggregation, correlation, comparison, summary statistics, sentiment analysis, and time-series analysis. Don’t forget to include plots during both the exploration and analysis phases. Creating plots along the way can reveal insights and interesting trends in the data that you might not notice if you wait until you’re preparing for your presentation. Presentation requirements will be further explained in the next module.